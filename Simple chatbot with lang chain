#import required libraries
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import streamlit as st
import os
from dotenv import load_dotenv
load_dotenv()


os.environ['LANGCHAIN_API_KEY']  = "your api key"
os.environ['OPENAI_API_KEY'] = "your api key"

# Prompt Ttemplete

prompt = ChatPromptTemplate(
    [
        ("system", "You are a helpful assistant. Please give response to the user queries"),
        ('user', 'Question:{question}')
    ]
)

# Streamlit
st.title("Langchain Demo")
input_texts = st.text_input("Search a topic")

#Calling LLM
llm = ChatOpenAI(model = "gpt-3.5-turbo")
output_parser = StrOutputParser()

#chaining the process
chain = prompt|llm|output_parser

if input_texts:
    st.write(chain.invoke({'question':input_texts}))




